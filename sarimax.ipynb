{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 22:55:00,849 - INFO - Loading bitcoin.csv\n",
      "2025-04-14 22:55:00,858 - INFO - Loading gold.csv\n",
      "2025-04-14 22:55:00,861 - INFO - Loading google_trends.csv\n",
      "2025-04-14 22:55:00,864 - INFO - Loading sp500.csv\n",
      "2025-04-14 22:55:00,867 - INFO - Loading treasury_3m.csv\n",
      "2025-04-14 22:55:00,870 - INFO - Loading treasury_10y.csv\n",
      "2025-04-14 22:55:00,872 - INFO - Loading copper.csv\n",
      "2025-04-14 22:55:00,877 - INFO - Loading oil.csv\n",
      "2025-04-14 22:55:00,879 - INFO - Loading unemployment.csv\n",
      "2025-04-14 22:55:00,883 - INFO - Loading MOEX.csv\n",
      "2025-04-14 22:55:00,886 - INFO - Loading SSE.csv\n",
      "2025-04-14 22:55:00,888 - INFO - Loading STOXX_600.csv\n",
      "2025-04-14 22:55:00,890 - INFO - Loading vix.csv\n",
      "2025-04-14 22:55:00,892 - INFO - Loading spgsci.csv\n",
      "2025-04-14 22:55:00,896 - INFO - Merging all dataframes\n",
      "2025-04-14 22:55:00,916 - INFO - Final dataset shape with lags/rolls: (794, 69)\n",
      "2025-04-14 22:55:00,917 - INFO - Backtest for month starting 2023-01-01\n",
      "2025-04-14 22:55:10,644 - INFO - Backtest for month starting 2023-02-01\n",
      "2025-04-14 22:55:20,687 - INFO - Backtest for month starting 2023-03-01\n",
      "2025-04-14 22:55:31,813 - INFO - Backtest for month starting 2023-04-01\n",
      "2025-04-14 22:55:49,131 - INFO - Backtest for month starting 2023-05-01\n",
      "2025-04-14 22:56:07,459 - INFO - Backtest for month starting 2023-06-01\n",
      "2025-04-14 22:56:26,373 - INFO - Backtest for month starting 2023-07-01\n",
      "2025-04-14 22:56:45,503 - INFO - Backtest for month starting 2023-08-01\n",
      "2025-04-14 22:57:10,937 - INFO - Backtest for month starting 2023-09-01\n",
      "2025-04-14 22:57:33,187 - INFO - Backtest for month starting 2023-10-01\n",
      "2025-04-14 22:57:57,023 - INFO - Backtest for month starting 2023-11-01\n",
      "2025-04-14 22:58:19,113 - INFO - Backtest for month starting 2023-12-01\n",
      "2025-04-14 22:58:46,092 - INFO - Backtest for month starting 2024-01-01\n",
      "2025-04-14 22:59:10,391 - INFO - Backtest for month starting 2024-02-01\n",
      "2025-04-14 22:59:37,724 - INFO - Backtest for month starting 2024-03-01\n",
      "2025-04-14 23:00:05,600 - INFO - Backtest for month starting 2024-04-01\n",
      "2025-04-14 23:00:32,874 - INFO - Backtest for month starting 2024-05-01\n",
      "2025-04-14 23:01:00,111 - INFO - Backtest for month starting 2024-06-01\n",
      "2025-04-14 23:01:29,362 - INFO - Backtest for month starting 2024-07-01\n",
      "2025-04-14 23:04:34,010 - INFO - Backtest for month starting 2024-08-01\n",
      "2025-04-14 23:07:33,617 - INFO - Backtest for month starting 2024-09-01\n",
      "2025-04-14 23:10:21,059 - INFO - Backtest for month starting 2024-10-01\n",
      "2025-04-14 23:12:59,107 - INFO - Backtest for month starting 2024-11-01\n",
      "2025-04-14 23:15:46,960 - INFO - Backtest for month starting 2024-12-01\n",
      "2025-04-14 23:18:26,840 - INFO - Backtest for month starting 2025-01-01\n",
      "2025-04-14 23:21:33,771 - INFO - Backtest for month starting 2025-02-01\n",
      "2025-04-14 23:24:18,826 - INFO - Backtest for month starting 2025-03-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Backtest  Train Size  Test Start        R2        MAE       RMSE  \\\n",
      "0          1         243  2023-01-01  0.639884   3.567644   4.696596   \n",
      "1          2         263  2023-02-01  0.442231   3.951232   4.944281   \n",
      "2          3         282  2023-03-01  0.507930   3.539787   4.126693   \n",
      "3          4         305  2023-04-01  0.345633   1.749195   2.411999   \n",
      "4          5         324  2023-05-01 -1.363027   5.319201   6.009797   \n",
      "5          6         346  2023-06-01 -2.867095  10.077607  10.697305   \n",
      "6          7         367  2023-07-01 -2.363279  10.124038  11.195012   \n",
      "7          8         387  2023-08-01  0.773276   2.056073   2.582181   \n",
      "8          9         410  2023-09-01  0.819497   2.940014   3.682682   \n",
      "9         10         430  2023-10-01  0.562876   3.784457   5.038851   \n",
      "10        11         452  2023-11-01  0.926585   2.078619   2.679495   \n",
      "11        12         473  2023-12-01  0.823805   2.282809   3.133692   \n",
      "12        13         493  2024-01-01 -1.169285   9.302325  10.668179   \n",
      "13        14         514  2024-02-01 -5.491037  13.609550  14.128271   \n",
      "14        15         534  2024-03-01 -0.606183   4.938311   5.944124   \n",
      "15        16         554  2024-04-01  0.790892   3.048169   3.625825   \n",
      "16        17         576  2024-05-01  0.665259   4.037756   4.783815   \n",
      "17        18         598  2024-06-01 -4.538742  12.689822  14.555980   \n",
      "18        19         617  2024-07-01 -2.264811  11.377908  12.593076   \n",
      "19        20         639  2024-08-01  0.217217  10.725430  13.362255   \n",
      "20        21         661  2024-09-01  0.819167   3.584181   4.219633   \n",
      "21        22         681  2024-10-01 -3.193473  10.426830  11.507251   \n",
      "22        23         704  2024-11-01 -1.201857  12.227687  13.481377   \n",
      "23        24         724  2024-12-01  0.403715   4.530870   5.900775   \n",
      "24        25         745  2025-01-01  0.147067   7.049627   8.369827   \n",
      "25        26         765  2025-02-01  0.565719   3.983087   4.666023   \n",
      "26        27         784  2025-03-01 -1.139186  12.698128  16.186051   \n",
      "\n",
      "        Order Seasonal Order          AIC  \n",
      "0   (1, 1, 1)  (0, 0, 1, 12)  1376.556501  \n",
      "1   (1, 1, 1)  (1, 0, 1, 12)  1489.308829  \n",
      "2   (1, 1, 1)  (1, 0, 1, 12)  1592.040763  \n",
      "3   (1, 1, 1)  (1, 0, 1, 12)  1721.648884  \n",
      "4   (1, 1, 1)  (0, 0, 1, 12)  1820.238602  \n",
      "5   (1, 1, 1)  (1, 0, 1, 12)  1936.771507  \n",
      "6   (1, 1, 1)  (1, 0, 1, 12)  2053.842521  \n",
      "7   (1, 1, 1)  (0, 0, 1, 12)  2154.500858  \n",
      "8   (1, 1, 1)  (1, 0, 1, 12)  2271.831849  \n",
      "9   (1, 1, 1)  (1, 0, 1, 12)  2373.978504  \n",
      "10  (1, 1, 1)  (1, 0, 1, 12)  2487.607100  \n",
      "11  (1, 1, 1)  (1, 0, 1, 12)  2591.863072  \n",
      "12  (1, 1, 1)  (1, 0, 1, 12)  2692.881254  \n",
      "13  (1, 1, 1)  (1, 0, 1, 12)  2812.424741  \n",
      "14  (1, 1, 1)  (0, 0, 1, 12)  2917.292016  \n",
      "15  (1, 1, 1)  (1, 0, 1, 12)  3030.091897  \n",
      "16  (1, 1, 1)  (1, 0, 1, 12)  3141.132381  \n",
      "17  (1, 1, 1)  (1, 0, 1, 12)  3246.225911  \n",
      "18  (1, 1, 1)  (1, 0, 1, 12)  3340.892492  \n",
      "19  (1, 1, 1)  (1, 0, 1, 12)  3473.076057  \n",
      "20  (1, 1, 1)  (0, 0, 1, 12)  3608.877587  \n",
      "21  (1, 1, 1)  (0, 0, 1, 12)  3714.757105  \n",
      "22  (1, 1, 1)  (0, 0, 1, 12)  3842.238809  \n",
      "23  (1, 1, 1)  (0, 0, 1, 12)  3962.799622  \n",
      "24  (1, 1, 1)  (0, 0, 1, 12)  4076.270012  \n",
      "25  (1, 1, 1)  (0, 0, 1, 12)  4183.770778  \n",
      "26  (1, 1, 1)  (0, 0, 1, 12)  4288.959258  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "data_path = \"data\"\n",
    "file_names = {\n",
    "    \"bitcoin\": \"bitcoin.csv\",\n",
    "    \"gold\": \"gold.csv\",\n",
    "    \"google_trends\": \"google_trends.csv\",\n",
    "    \"sp500\": \"sp500.csv\",\n",
    "    \"treasury_3m\": \"treasury_3m.csv\",\n",
    "    \"treasury_10y\": \"treasury_10y.csv\",\n",
    "    \"copper\": \"copper.csv\",\n",
    "    \"oil\": \"oil.csv\",\n",
    "    \"unemployment\": \"unemployment.csv\",\n",
    "    \"moex\": \"MOEX.csv\",\n",
    "    \"sse\": \"SSE.csv\",\n",
    "    \"stoxx\": \"STOXX_600.csv\",\n",
    "    \"vix\": \"vix.csv\",\n",
    "    \"spgsci\": \"spgsci.csv\"\n",
    "}\n",
    "\n",
    "data = {}\n",
    "for key, file in file_names.items():\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    if os.path.exists(file_path):\n",
    "        logging.info(f\"Loading {file}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \"timestamp\" not in df.columns:\n",
    "            logging.warning(f\"{file} skipped: no 'timestamp' column\")\n",
    "            continue\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        df.replace({'.': np.nan}, inplace=True)\n",
    "        for col in df.columns:\n",
    "            if col != \"timestamp\":\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        data[key] = df\n",
    "    else:\n",
    "        logging.warning(f\"{file} not found\")\n",
    "\n",
    "rename_map = {\n",
    "    \"bitcoin\": {\"Close\": \"bitcoin_close\", \"Open\": \"bitcoin_open\", \"High\": \"bitcoin_high\", \"Low\": \"bitcoin_low\", \"Volume\": \"bitcoin_volume\"},\n",
    "    \"gold\": {\"Close\": \"gold_close\", \"Open\": \"gold_open\", \"High\": \"gold_high\", \"Low\": \"gold_low\", \"Volume\": \"gold_volume\"},\n",
    "    \"oil\": {\"Close\": \"oil_close\", \"Open\": \"oil_open\", \"High\": \"oil_high\", \"Low\": \"oil_low\", \"Volume\": \"oil_volume\"},\n",
    "    \"copper\": {\"price\": \"copper_price\"},\n",
    "    \"google_trends\": {\"SPX\": \"google_spx\", \"ETF\": \"google_etf\", \"index fund\": \"google_index_fund\", \"sp500\": \"google_sp500\"},\n",
    "    \"unemployment\": {\"Unemployment\": \"unemployment_rate\"},\n",
    "    \"treasury_3m\": {\"Close\": \"treasury_3m\"},\n",
    "    \"treasury_10y\": {\"Close\": \"treasury_10y\"},\n",
    "    \"sp500\": {\"Close\": \"sp500_close\"},\n",
    "    \"moex\": {\"Close\": \"moex_close\"},\n",
    "    \"sse\": {\"Close\": \"sse_close\"},\n",
    "    \"stoxx\": {\"Close\": \"stoxx_close\"},\n",
    "    \"vix\": {\"Close\": \"vix_close\"},\n",
    "    \"spgsci\": {\"Close\": \"spgsci_close\"}\n",
    "}\n",
    "\n",
    "for key, renames in rename_map.items():\n",
    "    if key in data:\n",
    "        data[key] = data[key].rename(columns=renames)\n",
    "\n",
    "logging.info(\"Merging all dataframes\")\n",
    "sp500 = data[\"sp500\"]\n",
    "all_data = sp500[[\"timestamp\", \"sp500_close\"]]\n",
    "for key, df in data.items():\n",
    "    if key != \"sp500\":\n",
    "        all_data = all_data.merge(df, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "all_data.sort_values(\"timestamp\", inplace=True)\n",
    "all_data.fillna(method=\"ffill\", inplace=True)\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "def add_lag_rolling_features(df, base_cols, lags=[1, 3, 7], windows=[3, 7]):\n",
    "    for col in base_cols:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}_lag_{lag}\"] = df[col].shift(lag)\n",
    "        for window in windows:\n",
    "            df[f\"{col}_roll_mean_{window}\"] = df[col].rolling(window).mean()\n",
    "            df[f\"{col}_roll_std_{window}\"] = df[col].rolling(window).std()\n",
    "    return df\n",
    "\n",
    "key_features = [\"sp500_close\", \"vix_close\", \"bitcoin_close\", \"oil_close\"]\n",
    "all_data = add_lag_rolling_features(all_data, key_features)\n",
    "all_data.dropna(inplace=True)\n",
    "all_data = all_data.loc[:, all_data.nunique() > 1]\n",
    "logging.info(\"Final dataset shape with lags/rolls: %s\", all_data.shape)\n",
    "\n",
    "target = \"sp500_close\"\n",
    "exclude_cols = [\"timestamp\", target]\n",
    "exog_vars = [col for col in all_data.columns if col not in exclude_cols]\n",
    "\n",
    "results = []\n",
    "start_date = pd.Timestamp(\"2023-01-01\")\n",
    "end_date = pd.Timestamp(\"2025-03-01\")\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    logging.info(f\"Backtest for month starting {current_date.strftime('%Y-%m-%d')}\")\n",
    "    next_month = current_date + pd.DateOffset(months=1)\n",
    "\n",
    "    train = all_data[all_data[\"timestamp\"] < current_date]\n",
    "    test = all_data[(all_data[\"timestamp\"] >= current_date) & (all_data[\"timestamp\"] < next_month)]\n",
    "\n",
    "    if len(train) < 100 or len(test) < 10:\n",
    "        logging.warning(\"Skipping month due to insufficient data\")\n",
    "        current_date += pd.DateOffset(months=1)\n",
    "        continue\n",
    "\n",
    "    y_train = train[target]\n",
    "    y_test = test[target]\n",
    "    X_train = train[exog_vars]\n",
    "    X_test = test[exog_vars]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_model = None\n",
    "    best_order = None\n",
    "    best_seasonal_order = None\n",
    "\n",
    "    for p in [0, 1]:\n",
    "        for q in [0, 1]:\n",
    "            for P in [0, 1]:\n",
    "                for Q in [0, 1]:\n",
    "                    try:\n",
    "                        model = SARIMAX(\n",
    "                            y_train,\n",
    "                            exog=X_train_pca,\n",
    "                            order=(p, 1, q),\n",
    "                            seasonal_order=(P, 0, Q, 12),\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False\n",
    "                        )\n",
    "                        model_fit = model.fit(disp=False)\n",
    "                        if model_fit.aic < best_aic:\n",
    "                            best_aic = model_fit.aic\n",
    "                            best_model = model_fit\n",
    "                            best_order = (p, 1, q)\n",
    "                            best_seasonal_order = (P, 0, Q, 12)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    if best_model:\n",
    "        forecast = best_model.forecast(steps=len(X_test_pca), exog=X_test_pca)\n",
    "        r2 = r2_score(y_test, forecast)\n",
    "        mae = mean_absolute_error(y_test, forecast)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "\n",
    "        results.append({\n",
    "            \"Backtest\": len(results) + 1,\n",
    "            \"Train Size\": len(train),\n",
    "            \"Test Start\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"R2\": r2,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"Order\": best_order,\n",
    "            \"Seasonal Order\": best_seasonal_order,\n",
    "            \"AIC\": best_aic\n",
    "        })\n",
    "\n",
    "    current_date += pd.DateOffset(months=1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "results_df.to_csv(\"results/sarimax_backtest_lags_rolls.csv\", index=False)\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
