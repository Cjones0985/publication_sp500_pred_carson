{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72820f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Load datasets\n",
    "data_path = \"data\"\n",
    "file_names = {\n",
    "    \"bitcoin\": \"bitcoin.csv\",\n",
    "    \"gold\": \"gold.csv\",\n",
    "    \"google_trends\": \"google_trends.csv\",\n",
    "    \"sp500\": \"sp500.csv\",\n",
    "    \"treasury_3m\": \"treasury_3m.csv\",\n",
    "    \"treasury_10y\": \"treasury_10y.csv\",\n",
    "    \"copper\": \"copper.csv\",\n",
    "    \"oil\": \"oil.csv\",\n",
    "    \"unemployment\": \"unemployment.csv\",\n",
    "    \"moex\": \"MOEX.csv\",\n",
    "    \"sse\": \"SSE.csv\",\n",
    "    \"stoxx\": \"STOXX_600.csv\",\n",
    "    \"vix\": \"vix.csv\",\n",
    "    \"spgsci\": \"spgsci.csv\"\n",
    "}\n",
    "\n",
    "data = {}\n",
    "for key, file in file_names.items():\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    if os.path.exists(file_path):\n",
    "        logging.info(f\"Loading {file}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        if \"timestamp\" not in df.columns:\n",
    "            logging.warning(f\"{file} skipped: no 'timestamp' column\")\n",
    "            continue\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "        df.replace({'.': np.nan}, inplace=True)\n",
    "        for col in df.columns:\n",
    "            if col != \"timestamp\":\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        data[key] = df\n",
    "    else:\n",
    "        logging.warning(f\"{file} not found\")\n",
    "\n",
    "rename_map = {\n",
    "    \"bitcoin\": {\"Close\": \"bitcoin_close\", \"Open\": \"bitcoin_open\", \"High\": \"bitcoin_high\", \"Low\": \"bitcoin_low\", \"Volume\": \"bitcoin_volume\"},\n",
    "    \"gold\": {\"Close\": \"gold_close\", \"Open\": \"gold_open\", \"High\": \"gold_high\", \"Low\": \"gold_low\", \"Volume\": \"gold_volume\"},\n",
    "    \"oil\": {\"Close\": \"oil_close\", \"Open\": \"oil_open\", \"High\": \"oil_high\", \"Low\": \"oil_low\", \"Volume\": \"oil_volume\"},\n",
    "    \"copper\": {\"price\": \"copper_price\"},\n",
    "    \"google_trends\": {\"SPX\": \"google_spx\", \"ETF\": \"google_etf\", \"index fund\": \"google_index_fund\", \"sp500\": \"google_sp500\"},\n",
    "    \"unemployment\": {\"Unemployment\": \"unemployment_rate\"},\n",
    "    \"treasury_3m\": {\"Close\": \"treasury_3m\"},\n",
    "    \"treasury_10y\": {\"Close\": \"treasury_10y\"},\n",
    "    \"sp500\": {\"Close\": \"sp500_close\"},\n",
    "    \"moex\": {\"Close\": \"moex_close\"},\n",
    "    \"sse\": {\"Close\": \"sse_close\"},\n",
    "    \"stoxx\": {\"Close\": \"stoxx_close\"},\n",
    "    \"vix\": {\"Close\": \"vix_close\"},\n",
    "    \"spgsci\": {\"Close\": \"spgsci_close\"}\n",
    "}\n",
    "\n",
    "for key, renames in rename_map.items():\n",
    "    if key in data:\n",
    "        data[key] = data[key].rename(columns=renames)\n",
    "\n",
    "logging.info(\"Merging all dataframes\")\n",
    "sp500 = data[\"sp500\"]\n",
    "all_data = sp500[[\"timestamp\", \"sp500_close\"]]\n",
    "for key, df in data.items():\n",
    "    if key != \"sp500\":\n",
    "        all_data = all_data.merge(df, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "all_data.sort_values(\"timestamp\", inplace=True)\n",
    "all_data.fillna(method=\"ffill\", inplace=True)\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "def add_lag_rolling_features(df, base_cols, lags=[1, 3, 7], windows=[3, 7]):\n",
    "    for col in base_cols:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}_lag_{lag}\"] = df[col].shift(lag)\n",
    "        for window in windows:\n",
    "            df[f\"{col}_roll_mean_{window}\"] = df[col].rolling(window).mean()\n",
    "            df[f\"{col}_roll_std_{window}\"] = df[col].rolling(window).std()\n",
    "    return df\n",
    "\n",
    "key_features = [\"sp500_close\", \"vix_close\", \"bitcoin_close\", \"oil_close\"]\n",
    "all_data = add_lag_rolling_features(all_data, key_features)\n",
    "all_data.dropna(inplace=True)\n",
    "all_data = all_data.loc[:, all_data.nunique() > 1]\n",
    "logging.info(\"Final dataset shape with lags/rolls: %s\", all_data.shape)\n",
    "\n",
    "target = \"sp500_close\"\n",
    "exclude_cols = [\"timestamp\", target]\n",
    "exog_vars = [col for col in all_data.columns if col not in exclude_cols]\n",
    "\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, signif=0.05, name=''):\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    p_value = result[1]\n",
    "    print(f'ADF Test for {name}: p-value = {p_value}')\n",
    "    return p_value < signif\n",
    "\n",
    "def make_stationary(df, columns, signif=0.05):\n",
    "    stationary_df = df.copy()\n",
    "    for col in columns:\n",
    "        if not adf_test(df[col], signif=signif, name=col):\n",
    "            stationary_df[col] = df[col].diff().dropna()\n",
    "            print(f'--> Differenced {col}')\n",
    "        else:\n",
    "            print(f'--> {col} is already stationary')\n",
    "    return stationary_df\n",
    "\n",
    "# Make target and exogenous variables stationary\n",
    "all_data = make_stationary(all_data, [target] + exog_vars)\n",
    "all_data.dropna(inplace=True)\n",
    "\n",
    "results = []\n",
    "start_date = pd.Timestamp(\"2023-01-01\")\n",
    "end_date = pd.Timestamp(\"2025-03-01\")\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    logging.info(f\"Backtest for month starting {current_date.strftime('%Y-%m-%d')}\")\n",
    "    next_month = current_date + pd.DateOffset(months=1)\n",
    "\n",
    "    train = all_data[all_data[\"timestamp\"] < current_date]\n",
    "    test = all_data[(all_data[\"timestamp\"] >= current_date) & (all_data[\"timestamp\"] < next_month)]\n",
    "\n",
    "    if len(train) < 100 or len(test) < 10:\n",
    "        logging.warning(\"Skipping month due to insufficient data\")\n",
    "        current_date += pd.DateOffset(months=1)\n",
    "        continue\n",
    "\n",
    "    y_train = train[target]\n",
    "    y_test = test[target]\n",
    "    X_train = train[exog_vars]\n",
    "    X_test = test[exog_vars]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    pca = PCA(n_components=0.95)\n",
    "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "    X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "    best_aic = np.inf\n",
    "    best_model = None\n",
    "    best_order = None\n",
    "    best_seasonal_order = None\n",
    "\n",
    "    for p in [0, 1]:\n",
    "        for q in [0, 1]:\n",
    "            for P in [0, 1]:\n",
    "                for Q in [0, 1]:\n",
    "                    try:\n",
    "                        model = SARIMAX(\n",
    "                            y_train,\n",
    "                            exog=X_train_pca,\n",
    "                            order=(p, 1, q),\n",
    "                            seasonal_order=(P, 0, Q, 12),\n",
    "                            enforce_stationarity=False,\n",
    "                            enforce_invertibility=False\n",
    "                        )\n",
    "                        model_fit = model.fit(disp=False)\n",
    "                        if model_fit.aic < best_aic:\n",
    "                            best_aic = model_fit.aic\n",
    "                            best_model = model_fit\n",
    "                            best_order = (p, 1, q)\n",
    "                            best_seasonal_order = (P, 0, Q, 12)\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "    if best_model:\n",
    "        forecast = best_model.forecast(steps=len(X_test_pca), exog=X_test_pca)\n",
    "        r2 = r2_score(y_test, forecast)\n",
    "        mae = mean_absolute_error(y_test, forecast)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "\n",
    "        results.append({\n",
    "            \"Backtest\": len(results) + 1,\n",
    "            \"Train Size\": len(train),\n",
    "            \"Test Start\": current_date.strftime(\"%Y-%m-%d\"),\n",
    "            \"R2\": r2,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"Order\": best_order,\n",
    "            \"Seasonal Order\": best_seasonal_order,\n",
    "            \"AIC\": best_aic\n",
    "        })\n",
    "\n",
    "    current_date += pd.DateOffset(months=1)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "results_df.to_csv(\"results/sarimax_backtest_lags_rolls.csv\", index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db6c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, signif=0.05, name=''):\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    p_value = result[1]\n",
    "    print(f'ADF Test for {name}: p-value = {p_value}')\n",
    "    return p_value < signif\n",
    "\n",
    "def make_stationary(df, columns, signif=0.05):\n",
    "    stationary_df = df.copy()\n",
    "    for col in columns:\n",
    "        if not adf_test(df[col], signif=signif, name=col):\n",
    "            stationary_df[col] = df[col].diff().dropna()\n",
    "            print(f'--> Differenced {col}')\n",
    "        else:\n",
    "            print(f'--> {col} is already stationary')\n",
    "    return stationary_df\n",
    "\n",
    "# Example usage (adjust as needed):\n",
    "# target_col = 'sp500'\n",
    "# exog_cols = ['gold', 'oil', 'bitcoin', 'treasury_3m', 'treasury_10y', 'copper', 'unemployment']\n",
    "# df = make_stationary(df, [target_col] + exog_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e9017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, signif=0.05, name=''):\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    p_value = result[1]\n",
    "    print(f'ADF Test for {name}: p-value = {p_value}')\n",
    "    return p_value < signif\n",
    "\n",
    "def make_stationary(df, columns, signif=0.05):\n",
    "    stationary_df = df.copy()\n",
    "    for col in columns:\n",
    "        if not adf_test(df[col], signif=signif, name=col):\n",
    "            stationary_df[col] = df[col].diff().dropna()\n",
    "            print(f'--> Differenced {col}')\n",
    "        else:\n",
    "            print(f'--> {col} is already stationary')\n",
    "    return stationary_df\n",
    "\n",
    "# Example usage (adjust as needed):\n",
    "# target_col = 'sp500'\n",
    "# exog_cols = ['gold', 'oil', 'bitcoin', 'treasury_3m', 'treasury_10y', 'copper', 'unemployment']\n",
    "# df = make_stationary(df, [target_col] + exog_cols)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
