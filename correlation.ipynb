{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with S&P 500 Close:\n",
      "sp500_Close          1.000000\n",
      "bitcoin_Close        0.926377\n",
      "gold_Close           0.046201\n",
      "Google_sp500         0.209029\n",
      "Google_SPX          -0.282475\n",
      "Google_index fund    0.541297\n",
      "Google_ETF           0.522086\n",
      "Name: sp500_Close, dtype: float64\n",
      "\n",
      "Lagged Correlations:\n",
      "\n",
      "Correlation with S&P 500 Close lagged 7 days:\n",
      "sp500_Close          0.974138\n",
      "bitcoin_Close        0.923256\n",
      "gold_Close           0.061790\n",
      "Google_sp500         0.296010\n",
      "Google_SPX          -0.207706\n",
      "Google_index fund    0.579937\n",
      "Google_ETF           0.536218\n",
      "sp500_Close_lag7     1.000000\n",
      "Name: sp500_Close_lag7, dtype: float64\n",
      "\n",
      "Correlation with S&P 500 Close lagged 30 days:\n",
      "sp500_Close          0.902892\n",
      "bitcoin_Close        0.895362\n",
      "gold_Close           0.126349\n",
      "Google_sp500         0.404065\n",
      "Google_SPX          -0.129503\n",
      "Google_index fund    0.583891\n",
      "Google_ETF           0.502267\n",
      "sp500_Close_lag7     0.919040\n",
      "sp500_Close_lag30    1.000000\n",
      "Name: sp500_Close_lag30, dtype: float64\n",
      "\n",
      "Correlation with S&P 500 Close lagged 180 days:\n",
      "sp500_Close           0.362021\n",
      "bitcoin_Close         0.440475\n",
      "gold_Close            0.138370\n",
      "Google_sp500          0.434925\n",
      "Google_SPX            0.230972\n",
      "Google_index fund     0.197521\n",
      "Google_ETF            0.156594\n",
      "sp500_Close_lag7      0.385643\n",
      "sp500_Close_lag30     0.459946\n",
      "sp500_Close_lag180    1.000000\n",
      "Name: sp500_Close_lag180, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/1262064546.py:36: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlations = df.corr().loc[\"sp500_Close\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/1262064546.py:47: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/1262064546.py:47: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/1262064546.py:47: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# List of files to read\n",
    "files = {\n",
    "    \"bitcoin\": \"bitcoin.csv\",\n",
    "    \"gold\": \"gold.csv\",\n",
    "    \"sp500\": \"sp500.csv\",\n",
    "    \"treasury_3m\": \"treasury_3m.csv\",\n",
    "    \"treasury_10y\": \"treasury_10y.csv\",\n",
    "    \"google_trends\": \"google_trends.csv\"\n",
    "}\n",
    "\n",
    "# Read CSV files\n",
    "data = {}\n",
    "for key, file in files.items():\n",
    "    data[key] = pd.read_csv('data/' + file, parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "\n",
    "# Merge data on timestamp\n",
    "df = data[\"sp500\"][[\"Close\"]].rename(columns={\"Close\": \"sp500_Close\"})\n",
    "for key in [\"bitcoin\", \"gold\"]:\n",
    "    df = df.join(data[key][[\"Close\"]].rename(columns={\"Close\": f\"{key}_Close\"}), how=\"left\")\n",
    "\n",
    "for key in [\"treasury_3m\", \"treasury_10y\"]:\n",
    "    df = df.join(data[key], how=\"left\")\n",
    "\n",
    "# Rename Google Trends columns with prefix Google_\n",
    "if \"google_trends\" in data:\n",
    "    data[\"google_trends\"] = data[\"google_trends\"].rename(columns={col: f\"Google_{col}\" for col in data[\"google_trends\"].columns})\n",
    "    df = df.join(data[\"google_trends\"], how=\"left\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Calculate correlation of S&P 500 Close with other assets\n",
    "correlations = df.corr().loc[\"sp500_Close\"]\n",
    "print(\"Correlation with S&P 500 Close:\")\n",
    "print(correlations)\n",
    "\n",
    "# Lagging S&P 500 Close prices\n",
    "lags = [7, 30, 180]\n",
    "lagged_correlations = {}\n",
    "\n",
    "for lag in lags:\n",
    "    df[f\"sp500_Close_lag{lag}\"] = df[\"sp500_Close\"].shift(lag)\n",
    "    lagged_df = df.dropna()  # Drop NaNs introduced by shifting\n",
    "    lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
    "\n",
    "print(\"\\nLagged Correlations:\")\n",
    "for lag, corr in lagged_correlations.items():\n",
    "    print(f\"\\nCorrelation with S&P 500 Close lagged {lag} days:\")\n",
    "    print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: finbert_sentiment.csv not found. Skipping...\n",
      "Generating FinBERT sentiment data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297bc3bcd919459f8f5e32c4351d6754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/758 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e9e4412cfb4478a571b4521910c05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d3c71f12594afa8afb9a3424caa124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e270d3cd3eae4ce4b822de7d342325dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2023f0938dd4d318c5bf021337b1db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35533b7c2f554b4383a9d223cb45ff7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with S&P 500 Close:\n",
      "sp500_Close          1.000000\n",
      "bitcoin_Close        0.956150\n",
      "gold_Close          -0.456099\n",
      "Google_sp500        -0.916161\n",
      "Google_SPX          -0.889431\n",
      "Google_index fund    0.141491\n",
      "Google_ETF           0.204614\n",
      "sentiment_score           NaN\n",
      "Name: sp500_Close, dtype: float64\n",
      "\n",
      "Lagged Correlations:\n",
      "\n",
      "Correlation with S&P 500 Close lagged 7 days:\n",
      "sp500_Close          0.648315\n",
      "bitcoin_Close        0.532346\n",
      "gold_Close           0.194197\n",
      "Google_sp500        -0.334830\n",
      "Google_SPX          -0.265138\n",
      "Google_index fund   -0.265138\n",
      "Google_ETF          -0.052059\n",
      "sentiment_score           NaN\n",
      "sp500_Close_lag7     1.000000\n",
      "Name: sp500_Close_lag7, dtype: float64\n",
      "\n",
      "Correlation with S&P 500 Close lagged 30 days:\n",
      "sp500_Close         NaN\n",
      "bitcoin_Close       NaN\n",
      "gold_Close          NaN\n",
      "Google_sp500        NaN\n",
      "Google_SPX          NaN\n",
      "Google_index fund   NaN\n",
      "Google_ETF          NaN\n",
      "sentiment_score     NaN\n",
      "sp500_Close_lag7    NaN\n",
      "sp500_Close_lag30   NaN\n",
      "Name: sp500_Close_lag30, dtype: float64\n",
      "\n",
      "Correlation with S&P 500 Close lagged 180 days:\n",
      "sp500_Close          NaN\n",
      "bitcoin_Close        NaN\n",
      "gold_Close           NaN\n",
      "Google_sp500         NaN\n",
      "Google_SPX           NaN\n",
      "Google_index fund    NaN\n",
      "Google_ETF           NaN\n",
      "sentiment_score      NaN\n",
      "sp500_Close_lag7     NaN\n",
      "sp500_Close_lag30    NaN\n",
      "sp500_Close_lag180   NaN\n",
      "Name: sp500_Close_lag180, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/2646495243.py:66: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  correlations = df.corr().loc[\"sp500_Close\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/2646495243.py:77: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/2646495243.py:77: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
      "/var/folders/sd/x6b24fj17sg_pd8tj67xfp4r0000gn/T/ipykernel_81523/2646495243.py:77: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n",
    "# List of files to read\n",
    "files = {\n",
    "    \"bitcoin\": \"bitcoin.csv\",\n",
    "    \"gold\": \"gold.csv\",\n",
    "    \"sp500\": \"sp500.csv\",\n",
    "    \"treasury_3m\": \"treasury_3m.csv\",\n",
    "    \"treasury_10y\": \"treasury_10y.csv\",\n",
    "    \"google_trends\": \"google_trends.csv\",\n",
    "    \"finbert_sentiment\": \"finbert_sentiment.csv\"\n",
    "}\n",
    "\n",
    "data_folder = \"data\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Read CSV files\n",
    "data = {}\n",
    "for key, file in files.items():\n",
    "    file_path = os.path.join(data_folder, file)\n",
    "    if os.path.exists(file_path):\n",
    "        data[key] = pd.read_csv(file_path, parse_dates=[\"timestamp\"], index_col=\"timestamp\")\n",
    "    else:\n",
    "        print(f\"Warning: {file} not found. Skipping...\")\n",
    "\n",
    "# Fetch FinBERT sentiment data if missing\n",
    "if \"finbert_sentiment\" not in data:\n",
    "    print(\"Generating FinBERT sentiment data...\")\n",
    "    classifier = pipeline(\"sentiment-analysis\", model=\"ProsusAI/finbert\")\n",
    "    \n",
    "    # Example news data (replace with actual financial news dataset)\n",
    "    news_data = pd.DataFrame({\n",
    "        \"timestamp\": pd.date_range(start=\"2022-01-01\", periods=30, freq='D'),\n",
    "        \"headline\": [\"Stock market rises on positive earnings\" for _ in range(30)]\n",
    "    })\n",
    "    \n",
    "    news_data[\"sentiment_score\"] = news_data[\"headline\"].apply(lambda x: classifier(x)[0][\"score\"] * (1 if classifier(x)[0][\"label\"] == \"positive\" else -1))\n",
    "    news_data = news_data.drop(columns=[\"headline\"])\n",
    "    news_data.set_index(\"timestamp\", inplace=True)\n",
    "    news_data.to_csv(os.path.join(data_folder, \"finbert_sentiment.csv\"))\n",
    "    data[\"finbert_sentiment\"] = news_data\n",
    "\n",
    "# Merge data on timestamp\n",
    "df = data[\"sp500\"][[\"Close\"]].rename(columns={\"Close\": \"sp500_Close\"})\n",
    "for key in [\"bitcoin\", \"gold\"]:\n",
    "    df = df.join(data[key][[\"Close\"]].rename(columns={\"Close\": f\"{key}_Close\"}), how=\"left\")\n",
    "\n",
    "for key in [\"treasury_3m\", \"treasury_10y\"]:\n",
    "    df = df.join(data[key], how=\"left\")\n",
    "\n",
    "# Rename Google Trends columns with prefix Google_\n",
    "if \"google_trends\" in data:\n",
    "    data[\"google_trends\"] = data[\"google_trends\"].rename(columns={col: f\"Google_{col}\" for col in data[\"google_trends\"].columns})\n",
    "    df = df.join(data[\"google_trends\"], how=\"left\")\n",
    "\n",
    "# Add FinBERT sentiment data\n",
    "df = df.join(data[\"finbert_sentiment\"], how=\"left\")\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Calculate correlation of S&P 500 Close with other assets\n",
    "correlations = df.corr().loc[\"sp500_Close\"]\n",
    "print(\"Correlation with S&P 500 Close:\")\n",
    "print(correlations)\n",
    "\n",
    "# Lagging S&P 500 Close prices\n",
    "lags = [7, 30, 180]\n",
    "lagged_correlations = {}\n",
    "\n",
    "for lag in lags:\n",
    "    df[f\"sp500_Close_lag{lag}\"] = df[\"sp500_Close\"].shift(lag)\n",
    "    lagged_df = df.dropna()  # Drop NaNs introduced by shifting\n",
    "    lagged_correlations[lag] = lagged_df.corr().loc[f\"sp500_Close_lag{lag}\"]\n",
    "\n",
    "print(\"\\nLagged Correlations:\")\n",
    "for lag, corr in lagged_correlations.items():\n",
    "    print(f\"\\nCorrelation with S&P 500 Close lagged {lag} days:\")\n",
    "    print(corr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
